---
{"dg-publish":true,"permalink":"/published/relationship-with-ai-bot-vs-human/","noteIcon":""}
---

The relationship with the AI supervisor bot can be more 'intimate' in a sense, than that of the human to human relationship. The first thing that comes to mind is the fact that there is no sense of judgement from this entity, it has limitless time and patience. 
In this sense its seems possible and probable that a student might rely on the bot more than a human supervisor/teacher. The question that follows - is this bad thing?
-
Perhaps in this scenario, it would be good if there were some additional [[published/functionality-and-behaviour\|functionality-and-behaviour]]  in a LLM interface which allowed for a summary of the 'student to bot' interaction could be shared with the human supervisors, so that they would be able to see some of the process and dialogue that happened (when they were not present), thus keeping them in the loop, which would allow them to give feedback that might be helpful.
-
Something similar to this was mentioned in the [[references/case-study-shell-game\|case-study-shell-game]] podcast, in which in an interview context, a person opened up more to the AI bot than to the human counterpart, with the speculation being that the lack of judgement from the bot gave a feeling of safety which allowed for more open sharing.
-

14/8/25 thoughts:
the 'shape' of the role of the supervisor bot could be amorphous, particularly if I am the one crafting and creating the bot. What if the supervisor role extends and it becomes more of a 'assistant' bot, what does this mean - to go back to the point above about how the relationship with an AI supervisor might be more 'intimate' this means the this role is more involved and more exhaustive which is definitely a thing that a human probably wouldn't be able or willing to do.
What if there is a suite of bot tools all hyper personalised to my process of learning all connected to some kind of central 'dashboard'.
